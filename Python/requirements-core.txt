# RFSN GenAI Orchestrator - Core dependencies (Linux/Docker-safe)
# Keep this file free of MLX so Docker builds on Linux.

# Web Framework
fastapi==0.109.0
uvicorn[standard]==0.27.0
pydantic==2.5.3
python-multipart==0.0.6

# LLM Inference (llama-cpp optional, Ollama is default)
# llama-cpp-python==0.2.56  # Uncomment if using llama-cpp backend
# Note: Ollama uses HTTP API, no special deps needed

# JWT
PyJWT==2.8.0

# HTTP requests (for Ollama client and model downloads)
requests==2.31.0
tqdm==4.66.1

# Testing
pytest==7.4.4
pytest-asyncio==0.23.3
httpx==0.26.0

# Utilities
python-dotenv==1.0.0

# Static Files
aiofiles==23.2.1

# Learning Layer
numpy>=1.24

# TTS (Kokoro-ONNX - lightweight ~300MB model)
kokoro-onnx>=0.4.9
scipy
soundfile

# Semantic Memory
sentence-transformers==2.2.2
scikit-learn>=1.3.0

