<div align="center">

# üéÆ RFSN NPC Controller

<img src="https://img.shields.io/badge/version-10.2-blueviolet?style=for-the-badge" alt="Version 10.2"/>

**Production-Ready Streaming AI System for Real-Time NPC Dialogue**

[![Python 3.10+](https://img.shields.io/badge/Python-3.10+-3776AB?style=flat-square&logo=python&logoColor=white)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-009688?style=flat-square&logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com/)
[![Tests](https://img.shields.io/badge/Tests-280%20Passing-success?style=flat-square&logo=pytest)](Python/tests/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow?style=flat-square)](LICENSE)
[![Ollama](https://img.shields.io/badge/Ollama-LLM-black?style=flat-square)](https://ollama.ai/)

*Intelligent NPCs with semantic action selection, world model prediction, adaptive learning, and real-time TTS*

---

[**Features**](#-features) ‚Ä¢ [**Quick Start**](#-quick-start) ‚Ä¢ [**Architecture**](#-architecture) ‚Ä¢ [**API**](#-api-reference) ‚Ä¢ [**Learning**](#-learning-layer) ‚Ä¢ [**Performance**](#-performance)

</div>

---

## ‚ú® Features

### üß† Core Intelligence

| Feature | Description |
|---------|-------------|
| **Semantic Action Selection** | World model predicts outcomes and scores 32 discrete NPC actions |
| **Contextual Bandits** | Thompson sampling with adaptive exploration learns optimal dialogue styles |
| **Temporal Memory** | Short-term experience buffer enables anticipatory reasoning |
| **Hybrid NLU** | LLM-powered intent classification with regex fallback via Ollama |
| **Emotional Modeling** | VAD-based (Valence/Arousal/Dominance) emotional state with decay |
| **Sentiment Tracking** | Multi-player longitudinal sentiment analysis with trend detection |

### üéôÔ∏è Voice & Speech

| Feature | Description |
|---------|-------------|
| **Dual TTS Router** | Chatterbox-Turbo + Chatterbox-Full with automatic intensity-based selection |
| **Lazy Model Loading** | Full model (~2GB VRAM) loaded only on first HIGH intensity request |
| **LRU Audio Cache** | 100 clips, 5-min TTL for repeated lines |
| **Kokoro Fallback** | Graceful CPU-only degradation when CUDA unavailable |

### üõ°Ô∏è Production Hardening

- ‚úÖ **280+ Tests** ‚Äî Comprehensive coverage including streaming, learning, world model, and persistence
- ‚úÖ **Dot-Path Config** ‚Äî Nested config access (`llm.temperature`) with hot-reload support
- ‚úÖ **Zero Race Conditions** ‚Äî Deque+Condition queue pattern eliminates task_done/join bugs
- ‚úÖ **Atomic State Swaps** ‚Äî RuntimeState prevents half-applied config during hot reloads
- ‚úÖ **Full Persistence** ‚Äî Temporal memory, emotional states, and bandit weights survive restarts
- ‚úÖ **Safety Rules** ‚Äî Hard overrides prevent learned stupidity in combat/trust/quest contexts

---

## üöÄ Quick Start

### Prerequisites

- **Python 3.10+** (required for Kokoro TTS)
- **4GB RAM** minimum
- **Ollama** for local LLM inference

### Installation

```bash
# Clone the repository
git clone https://github.com/dawsonblock/RFSN_NPC_CONTROLLER.git
cd RFSN_NPC_CONTROLLER

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# Install dependencies
pip install -r Python/requirements-core.txt
pip install kokoro-onnx

# Install & start Ollama (macOS)
brew install ollama
ollama serve &
ollama pull llama3.2

# Launch the server
cd Python
python -m uvicorn orchestrator:app --host 0.0.0.0 --port 8000
```

### Access Points

| Endpoint | URL |
|----------|-----|
| **API Server** | `http://localhost:8000` |
| **Dashboard** | `http://localhost:8000` |
| **Mobile UI** | `http://localhost:8080` (run `python mobile_chat/server.py`) |

### Docker

```bash
docker build -t rfsn-npc .
docker run -p 8000:8000 rfsn-npc
```

---

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     RFSN NPC Controller v10.2                        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ   FastAPI    ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Streaming   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Voice Router       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   Server     ‚îÇ    ‚îÇ   Engine     ‚îÇ    ‚îÇ  (Turbo/Full/Kokoro) ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ         ‚îÇ                    ‚îÇ                       ‚îÇ              ‚îÇ
‚îÇ         ‚ñº                    ‚ñº                       ‚ñº              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ   Hybrid     ‚îÇ    ‚îÇ DequeSpeech  ‚îÇ    ‚îÇ    Audio Player      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   NLU Gate   ‚îÇ    ‚îÇ    Queue     ‚îÇ    ‚îÇ    (Async/Stream)    ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ         ‚îÇ                    ‚îÇ                                      ‚îÇ
‚îÇ         ‚ñº                    ‚ñº                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ   Temporal   ‚îÇ    ‚îÇ World Model  ‚îÇ    ‚îÇ   Emotional State    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   Memory     ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ (Prediction) ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ   (VAD + Decay)      ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ         ‚îÇ                    ‚îÇ                       ‚îÇ              ‚îÇ
‚îÇ         ‚ñº                    ‚ñº                       ‚ñº              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ   Bandit     ‚îÇ    ‚îÇAction Scorer ‚îÇ    ‚îÇ  Sentiment Tracker   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   Learner    ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ (32 Actions) ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ  (Multi-Player)      ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Key Components

| Component | Purpose | Location |
|-----------|---------|----------|
| **Orchestrator** | FastAPI server, lifecycle hooks | `Python/orchestrator.py` |
| **Streaming Engine** | Token processing, sentence detection | `Python/streaming_engine.py` |
| **Voice Router** | Dual-TTS with lazy load, LRU cache | `Python/voice_router.py` |
| **World Model** | Predicts state transitions | `Python/world_model.py` |
| **Action Scorer** | Scores 32 candidate actions | `Python/action_scorer.py` |
| **NPC Action Bandit** | Thompson sampling learner | `Python/learning/npc_action_bandit.py` |
| **Temporal Memory** | Short-term experience buffer | `Python/learning/temporal_memory.py` |
| **Emotional State** | VAD modeling with decay | `Python/emotional_tone.py` |
| **Sentiment Tracker** | Longitudinal player analysis | `Python/learning/sentiment_tracker.py` |
| **Intent Extraction** | Hybrid LLM+regex classification | `Python/intent_extraction.py` |
| **State Machine** | Invariant-validated state transitions | `Python/state_machine.py` |
| **Hot Config** | Dot-path nested config with hot-reload | `Python/hot_config.py` |

---

## üì° API Reference

### Streaming Dialogue

```http
POST /api/dialogue/stream
Content-Type: application/json

{
  "npc_name": "Jarl Balgruuf",
  "user_input": "Tell me about Whiterun."
}
```

**Response**: Server-Sent Events (SSE)

```
data: {"sentence": "Whiterun is a great city.", "is_final": false, "latency_ms": 150}
data: {"sentence": "We welcome all travelers.", "is_final": true, "latency_ms": 280}
```

### Memory Management

```http
GET  /api/memory/{npc_name}/stats       # Get memory statistics
POST /api/memory/{npc_name}/safe_reset  # Reset with backup
GET  /api/memory/{npc_name}/backups     # List available backups
```

### Performance Tuning

```http
POST /api/tune-performance
{
  "temperature": 0.7,
  "max_tokens": 150,
  "max_queue_size": 3
}
```

### Health & Metrics

```http
GET /api/health           # Health check
WS  /ws/metrics           # WebSocket metrics stream
```

---

## ü§ñ Learning Layer

### Contextual Bandit

The system uses Thompson sampling with adaptive exploration to learn optimal dialogue styles per NPC:

| Mode | Description |
|------|-------------|
| `TERSE_DIRECT` | Short, factual responses (3-4 sentences) |
| `WARM_FRIENDLY` | Empathetic, relational responses |
| `LORE_RICH` | Detailed world-building responses |
| `PLAYFUL_WITTY` | Humorous, light-hearted responses |
| `FORMAL_RESPECTFUL` | Distant, proper responses |
| `NEUTRAL_BALANCED` | Default balanced approach |

### Safety Rules

Hard overrides prevent learned stupidity:

| Condition | Override |
|-----------|----------|
| **Combat + Fear > 0.7** | Forces `FLEE` action |
| **Trust < 0.1** | Forbids `ACCEPT`, `OFFER`, `HELP` |
| **Quest Active** | Biases toward `HELP`, `AGREE` |

---

## üéôÔ∏è Voice Router

Intelligent dual-TTS engine with automatic model selection:

| Intensity | Engine | Use Case | Exaggeration |
|-----------|--------|----------|--------------|
| **LOW** | Chatterbox-Turbo | Guards, shopkeepers, barks | 0.3 |
| **MEDIUM** | Chatterbox-Turbo | Companion casual chat | 0.6 |
| **HIGH** | Chatterbox-Full | Memory callbacks, relationship moments | 0.8 |

**Optimizations:**

- üöÄ **Lazy Loading** ‚Äî Full model loaded only when needed
- üíæ **LRU Cache** ‚Äî 100 clips with 5-minute TTL
- ‚ö° **Precompute** ‚Äî Intensity cached for 5 seconds
- üîÑ **Fallback** ‚Äî Graceful Kokoro degradation

---

## ‚ö° Performance

### Benchmarks

| Metric | Target | Actual |
|--------|--------|--------|
| First Token Latency | <1.5s | ~1.2s |
| Sentence Detection | <50ms | ~30ms |
| TTS Processing | <100ms | ~80ms |
| Queue Throughput | 10/s | 12/s |

### Optimizations

- **Deque+Condition Queue** ‚Äî Eliminates race conditions
- **Atomic Drop Policy** ‚Äî Drop runs under same lock as worker
- **Pre-compiled Regex** ‚Äî No hot-path compilation overhead
- **Config Snapshots** ‚Äî Per-request snapshots prevent mid-stream changes

---

## üß™ Testing

```bash
# Run all tests
cd Python && python -m pytest tests/ -v

# Specific categories
pytest tests/test_learning*.py -v          # Learning layer
pytest tests/test_world_model*.py -v       # World model
pytest tests/test_voice_router.py -v       # Voice routing
pytest tests/test_production.py -v         # Production scenarios
```

### Coverage

| Category | Tests |
|----------|-------|
| Core Functionality | 165+ |
| Learning Layer | 45+ |
| World Model | 25+ |
| Voice Router | 30+ |
| State Machine & Config | 15 |
| **Total** | **280+** |

---

## üîß Configuration

### `config.json`

```json
{
  "llm": {
    "backend": "ollama",
    "ollama_host": "http://localhost:11434",
    "ollama_model": "llama3.2",
    "temperature": 0.7,
    "max_tokens": 150
  },
  "tts": {
    "backend": "chatterbox",
    "chatterbox": {
      "device": "cuda",
      "default_exaggeration": 0.5
    }
  },
  "learning": {
    "temporal_memory": { "enabled": true, "max_size": 50 },
    "nuance_variants": { "enabled": true }
  }
}
```

**Dot-path access** ‚Äî Access nested values with `config.get("llm.temperature")

```

### Environment Variables

```bash
export RFSN_PORT=8000
export RFSN_HOST=0.0.0.0
export RFSN_LOG_LEVEL=DEBUG
```

---

## üìÅ Project Structure

```
RFSN_NPC_CONTROLLER/
‚îú‚îÄ‚îÄ Python/
‚îÇ   ‚îú‚îÄ‚îÄ orchestrator.py         # FastAPI server
‚îÇ   ‚îú‚îÄ‚îÄ streaming_engine.py     # Core streaming logic
‚îÇ   ‚îú‚îÄ‚îÄ voice_router.py         # Dual-TTS routing
‚îÇ   ‚îú‚îÄ‚îÄ world_model.py          # State prediction
‚îÇ   ‚îú‚îÄ‚îÄ action_scorer.py        # Action evaluation
‚îÇ   ‚îú‚îÄ‚îÄ emotional_tone.py       # VAD emotional state
‚îÇ   ‚îú‚îÄ‚îÄ intent_extraction.py    # Hybrid NLU
‚îÇ   ‚îú‚îÄ‚îÄ learning/               # Contextual bandit layer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ npc_action_bandit.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ temporal_memory.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sentiment_tracker.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ event_logger.py
‚îÇ   ‚îî‚îÄ‚îÄ tests/                  # 290+ tests
‚îú‚îÄ‚îÄ Dashboard/                  # Metrics visualization
‚îú‚îÄ‚îÄ mobile_chat/                # iOS-optimized UI
‚îú‚îÄ‚îÄ config.json                 # Configuration
‚îî‚îÄ‚îÄ README.md
```

---

## üìà Changelog

### v10.2 (Current) ‚Äî Surgical Upgrade & Stabilization

- **NPCAction Case Fix** ‚Äî State machine now normalizes action case correctly
- **Dot-Path Config** ‚Äî Nested config access (`llm.temperature`) with hot-reload
- **Prompt Consolidation** ‚Äî Removed duplicate `prompting/` module (‚Äì692 LOC)
- **IntentGate Optimization** ‚Äî Per-sentence validation instead of per-chunk
- **Reward Normalization** ‚Äî Per-component logging with bounded output
- 280+ tests with new state machine and config coverage

### v10.1 ‚Äî Voice Router & Optimizations

- **Dual-TTS Voice Router** with lazy loading and LRU cache
- **Intensity-based routing** between Turbo and Full models
- **Precomputation caching** for stable NPC states

### v10.0 ‚Äî Persistence & Emotional States

- **Temporal Memory Persistence** across restarts
- **VAD Emotional State** with time-based decay
- **LLM Intent Classification** via Ollama
- **Sentiment Tracking** with trend detection
- **Adaptive Exploration** decay from 30% to 2%

### v9.0 ‚Äî Thread-Safe Queue Rewrite

- **Deque+Condition queue** replaces queue.Queue
- **Atomic drop policy** eliminates race conditions
- **RuntimeState** for safe config hot-reloads

[View Full Changelog](CHANGELOG.md)

---

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Run tests (`pytest tests/ -v`)
4. Commit changes (`git commit -m 'Add amazing feature'`)
5. Push to branch (`git push origin feature/amazing-feature`)
6. Open a Pull Request

---

## üìÑ License

MIT License ‚Äî see [LICENSE](LICENSE) for details

---

<div align="center">

## üîó Links

[**GitHub**](https://github.com/dawsonblock/RFSN_NPC_CONTROLLER) ‚Ä¢ [**Issues**](https://github.com/dawsonblock/RFSN_NPC_CONTROLLER/issues) ‚Ä¢ [**Discussions**](https://github.com/dawsonblock/RFSN_NPC_CONTROLLER/discussions)

---

**Made with ‚ù§Ô∏è for immersive NPC interactions**

‚≠ê **Star this repo if you find it useful!**

</div>
